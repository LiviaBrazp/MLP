{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando o script para que o algoritmo seja processado na placa do video do PC\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential  \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        #Alocar memória de vídeo de forma dinâmica\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "#Agora defina o modelo\n",
    "with tf.device('/GPU:0'):\n",
    "    model = Sequential()\n",
    "   \n",
    "############################################### PREVISÃO PARA VALORES DIARIOS ###############################################################################################\n",
    "\n",
    "#Preparando o algoritmo MLP para previsões da Eto diaria\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Carregar o banco de dados\n",
    "dados = pd.read_csv('caminho_do_arquivo.csv', sep=';')  \n",
    "dados['datona'] = pd.to_datetime(dados['datona'], format='%d/%m/%Y') #Converter para formato de data\n",
    "\n",
    "#\"datona\" é como esta nomeada a coluna contendo as informações de data, altere essa variavel de acordo com a nomeação do seu banco de dados\n",
    "\n",
    "print(dados.head())\n",
    "print(dados.columns)\n",
    "\n",
    "dados = dados.sort_values('datona')  #Ordenar os dados\n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        sequence = data.iloc[i:i + window_size]\n",
    "        sequences.append(sequence.values)\n",
    "    return sequences\n",
    "\n",
    "window_size = 30  #Tamanho da janela de previsão\n",
    "sequences = create_sequences(dados, window_size)\n",
    "\n",
    "#Converter para numpy array\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "#Separar features e target\n",
    "X = sequences[:, :-1, 1:]  #Features (removendo a coluna 'datona' e mantendo as outras)\n",
    "y = sequences[:, -1, -1]  #Target \n",
    "\n",
    "#Dividir em conjunto de treinamento e teste\n",
    "train_size = int(0.85 * len(sequences)) #O tamanho do conjunto de treino pode ser ajustado\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "#Verificando a quantidade de dados nos conjuntos de treino e teste\n",
    "print(f\"Quantidade de dados no conjunto de treinamento: {len(X_train)} amostras\")\n",
    "print(f\"Quantidade de dados no conjunto de teste: {len(X_test)} amostras\")\n",
    "print(f\"Quantidade de rótulos no conjunto de treinamento: {len(y_train)} amostras\")\n",
    "print(f\"Quantidade de rótulos no conjunto de teste: {len(y_test)} amostras\")\n",
    "\n",
    "#Conversão para float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "#Definindo a arquitetura da rede\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(256, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(128, activation='sigmoid', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='sigmoid', kernel_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Dense(32, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Compilando o modelo\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "#Adicionando a função early stopping para evitar o overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)  #Monitora a perda de validação e para o treinamento após 50 épocas se não houver melhoria\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=90, validation_data=(X_test, y_test), callbacks=[early_stopping])  #Treina o modelo com parada antecipada\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plota o histórico de treinamento e validação\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Faz as previsões com o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Calcula o RMSE (Root Mean Squared Error)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "#Calcula o MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "#Calcula o MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "#Número de dias futuros para prever\n",
    "num_days = 15  #Valor ajustavel\n",
    "\n",
    "#Define a sequência inicial para fazer as previsões\n",
    "sequence = X_test[-1].reshape(1, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "#Lista para armazenar as previsões diárias\n",
    "daily_predictions = []\n",
    "\n",
    "#Número de horas por dia (considerando 24 horas por dia)\n",
    "hours_per_day = 24\n",
    "\n",
    "for day in range(num_days):\n",
    "    next_prediction = model.predict(sequence)\n",
    "    daily_predictions.append(next_prediction[0, 0])\n",
    "    sequence = np.roll(sequence, -hours_per_day, axis=1) \n",
    "    sequence[0, -hours_per_day:] = next_prediction\n",
    "\n",
    "#Exibe as previsões para os próximos 15 dias (diariamente)\n",
    "print(\"Previsões para os próximos 15 dias:\")\n",
    "print(daily_predictions)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Cria um DataFrame com as previsões diárias\n",
    "df_daily_predictions = pd.DataFrame(daily_predictions, columns=['Predictions'])\n",
    "\n",
    "#Adiciona uma coluna com a data para cada previsão diária\n",
    "start_date = dados['datona'].iloc[-1] + pd.Timedelta(days=1)  \n",
    "date_range = pd.date_range(start=start_date, periods=len(daily_predictions), freq='D')\n",
    "df_daily_predictions['Date'] = date_range\n",
    "\n",
    "#Exibe as previsões diárias no DataFrame\n",
    "print(df_daily_predictions)\n",
    "\n",
    "#Exporta para um arquivo Excel\n",
    "df_daily_predictions.to_excel('MLP_diario.xlsx', index=False)\n",
    "\n",
    "\n",
    "############################################### PREVISÃO PARA VALORES HORARIOS ###############################################################################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Carrega o banco de dados\n",
    "dados = pd.read_csv('caminho_do_arquivo.csv', sep=';', parse_dates=['datona'], dayfirst=True)\n",
    "\n",
    "print(dados.head())\n",
    "print(dados.columns)\n",
    "\n",
    "dados = dados.sort_values('datona')  #Ordenar os dados \n",
    "\n",
    "def create_sequences(data, window_size):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        sequence = data.iloc[i:i + window_size]\n",
    "        sequences.append(sequence.values)\n",
    "    return sequences\n",
    "\n",
    "window_size = 90  #Tamanho da janela\n",
    "sequences = create_sequences(dados, window_size)\n",
    "\n",
    "#Converte para numpy array\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "#Separa features e target\n",
    "X = sequences[:, :-1, 1:]  #Features (remover a coluna 'datona' e manter as outras)\n",
    "y = sequences[:, -1, -1]  #Target \n",
    "\n",
    "#Dividindi em conjunto de treinamento e teste\n",
    "train_size = int(0.8 * len(sequences)) #Valor ajustavel\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "#Verifica a quantidade de dados nos conjuntos de treino e teste\n",
    "print(f\"Quantidade de dados no conjunto de treinamento: {len(X_train)} amostras\")\n",
    "print(f\"Quantidade de dados no conjunto de teste: {len(X_test)} amostras\")\n",
    "print(f\"Quantidade de rótulos no conjunto de treinamento: {len(y_train)} amostras\")\n",
    "print(f\"Quantidade de rótulos no conjunto de teste: {len(y_test)} amostras\")\n",
    "\n",
    "\n",
    "#Conversão para float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "#Definindo o modelo MLP\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "#Compilando o modelo\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "#Adicionando a função early stopping para evitar o overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)  #Monitora a perda de validação e para o treinamento após 50 épocas se não houver melhoria\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=3000, batch_size=90, validation_data=(X_test, y_test), callbacks=[early_stopping])  #Treina o modelo com parada antecipada\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Faz as previsões com o conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Calcula o RMSE (Root Mean Squared Error)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', rmse)\n",
    "\n",
    "#Calcula o MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "\n",
    "#Calcula o MAE (Mean Absolute Error)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE:', mae)\n",
    "\n",
    "#Define o número de horas por dia\n",
    "hours_per_day = 24\n",
    "\n",
    "#Define o número de dias futuros para prever\n",
    "num_days = 15\n",
    "\n",
    "#Define a sequência inicial para fazer as previsões\n",
    "sequence = X_test[-1].reshape(1, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "#Lista para armazenar as previsões\n",
    "predictions = []\n",
    "\n",
    "for day in range(num_days):\n",
    "    for hour in range(hours_per_day):\n",
    "        next_prediction = model.predict(sequence)\n",
    "        predictions.append(next_prediction[0, 0])  \n",
    "        sequence = np.roll(sequence, -1, axis=1)  \n",
    "        sequence[0, -1] = next_prediction \n",
    "\n",
    "#Exibe as previsões para os próximos 15 dias (cada dia com 24 horas)\n",
    "print(\"Previsões para os próximos 15 dias (24 horas por dia):\")\n",
    "print(predictions)\n",
    "\n",
    "#Exporta para um arquivo Excel\n",
    "df_predictions.to_excel('MLP_horario.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
